// # Parsing Pocket Lisp 
//
// Pocket Lisp is a "Lisp" dialect minimal and easy to implement.
// It does not contain most of the interesting things you'd see in
// a language like Scheme, but maintains syntax and constructs that
// are similar. For example, an expression like `1 + (2 * 3)` is
// expressed as `(+ 1 (* 2 3))` in Pocket Lisp. This is often called
// "prefix" notation, because the operation comes before the arguments,
// rather than going between them.
//
// We want to parse Pocket Lisp programs, which will be provided in
// plain text form, into something that's easier to work with. We
// want to know what is a number, and what is a function application,
// and so on. And to do so we need a parser.
//
// Lingua is a language that allows us to describe parsers. Behind the
// scenes Lingua is based on the Parsing Expression Grammar ([PEG])
// concept, a more recent contribution to parsing theory which makes
// it easier to write parsers by combining several different parts
// into a single one. Essentially, you describe what you expect the
// text to look like with a pattern, and your parser will then "match"
// anything that fits this pattern.
//
// The big difference from PEG to other ways of describing these patterns
// is that, in PEG, if you say "an operator can be '+', '-', or '++'",
// the parser will try each of these *in the order you wrote*. This is
// PEG's way of disambiguating particular sentences in a program. In
// this example, if the input program was `++`, our PEG grammar would
// actually match only the first one: our result would be `+`. That's
// because, when we try `+` first, we'll look at the input and go "Oh,
// hey, that does look like '+'. Neat! Let's use this one", and
// blissfully ignore the rest, because there are no more patterns to
// match.
//
// PEGs call this an "ordered choice". In Lingua, it's written with the
// `first choice | second choice` notation, so keep this idea in mind
// when reading the patterns below.
//
// Under the hood, Lingua uses [Ohm]. Ohm is an implementation of PEG
// that, among other things, supports the idea of [left recursion].
// That is, say you have a grammar that looks like this:
//
//     expr = expr "+" expr
//          | number
//
// The pattern says that an expression either looks like `1 + 2`, or like
// a number. But remember that PEGs have this idea of "ordered choice".
// In regular PEG implementations, we would try to match the `expr` pattern
// and see `expr`. "Oh, cool, I'll try to match `expr` then!". But the first
// thing we do when matching `expr` is go back to trying to match
// `expr`---we're stuck in the loop forever.
//
// Ohm solves this by keeping track of what has already been tried. If we
// try to match `expr` and see that we had done that before and it failed,
// we'll move on to the next alternative. So the parser goes "Oh, I need
// to match expr, and it says here I should try `expr '+' expr`," follows
// `expr` again and looks at it, "Welp! Here it says I need to match `expr`,
// but I already tried that before and that led me nowhere! I will ignore
// this and look at something else. Oh, `number`. Yeah, I could try that
// one!".
//
// Lisp dialects do not require left recursion, but this will be present
// in most other programming language grammars.
//
// ---
// [PEG]: https://en.wikipedia.org/wiki/Parsing_expression_grammar
// [Ohm]: https://ohmlang.github.io/
// [left recursion]: https://en.wikipedia.org/wiki/Left_recursion


// ## What's a "Pocket Lisp sructure"?
// 
// We could jump straight into defining what Pocket Lisp programs look
// like---into our grammar. But Lingua actually wants us to think about
// what structures we want out of parsing something[1]. So, before we get
// into grammars, we will discuss the Abstract Syntax Tree (AST) that
// we want out of it.
//
// An AST describes the important aspects of the program text in a "tree"
// format. For example, if we parse the program `(+ 1 (* 2 3)) ;; hello`
// we would likely get a tree that looks like this:
//
//     o <function application> +
//     |--o <number> 1
//     `--o <function application> *
//        |--o <number> 2
//        `--o <number> 3
//
// Note how this tree has no information about spaces or the little "hello"
// comment at the end. The goal is to keep the important pieces that our
// little virtual machine is going to use and discard everything else.
//
// Well, this is only half-true. We want this tree to be as simple as possible,
// but we still want some information about the original source code. That's
// because showing good error messages to users is still important! If we use
// the a tree like the one above, and somehow `*` fails to execute, we don't
// want to tell the user "failed to execute *". FAILED WHERE? What's the context?
// What do I have to fix? How do I even figure out how it failed? We want enough
// information in the tree to allow us to answer those questions---and this is
// often done by relating errors back to the program users wrote.
//
// Luckily, Lingua handles this mostly automatically for us. So in all of our
// node definitions below we'll have a `pos: interval` field. What this means
// is that the node will include all of the relevant information that allows
// us to know where it was originally written, and how it was written.
//
// In essence, this "interval" would allow us to improve the error message
// above and present instead:
//
//     Error: failed to execute *
//
//     Line 1, column 6
//     > 6 | (+ 1 (* 2 3)) ;; hello
//                ^^^^^^^
//
// Indeed, the "interval" type will already have a method to render this
// annotated source code as shown above, no additional work needed on us!
//
// Ahem. Let's get back to our AST. For Pocket Lisp we really have two
// different kinds of things that we want to track:
//
//   - Programs: at the top level we have a program. I can write something
//     like:
//
//         (display "Hello")
//         (display "World")
//
//     This is a program that contains two function calls.
//
//  - Forms: Every expression in a Pocket Lisp program is called a "form".
//    So something like `(+ 1 2)` is a function application form, and
//    something like `1` is a number form.
//
// ---
// [1]: Defining an AST is not a *requirement* in Lingua. You can indeed 
//      experiment with your grammar without thinking about ASTs at all
//      at first. In this case Lingua will give you a Concrete Syntax Tree
//      (or CST). It's a tree representation that closely matches how you've
//      structured your grammar.

// ## The Pocket Lisp AST
//
// As previously mentioned, for our AST we'll have two cases. The first one
// is the `plisp_program`. Lingua is a bit weird in the syntactical choice
// here because it uses underscores instead of hyphens (but this is subject
// to change). Part of this is that Lingua has multiple backends. It can
// generate Crochet code and TypeScript code.
//
// Our `plisp_program` (which will be translated to Crochet as `plisp-program`)
// will hold information about the source of the program (in the `pos` field),
// and will hold the list of forms that the program contains.
//
// NOTE: The `field: type` syntax is required; Lingua has *typed* semantics. However,
// type checking is currently only performed at runtime.
//
type plisp_program(pos: interval, forms: list<plisp_form>)

// Then we have our forms. Here a form can be one of many things, and Lingua
// uses a more conventional notation for describing this (if one is familiar
// with functional languages like OCaml and Haskell). There is no subtyping
// in Lingua, so these one-of types are the only way of describing a type
// that has multiple, more specific forms.
//
type plisp_form =
  // A `procedure` is a form that describes the definition of a function.
  // Here we care about what name the user wants to give the function,
  // what the name of its parameters are, and what we should execute when
  // the function is called (its body).
  //
  // Lisp dialects often allow the same function to take a variable amount
  // of arguments. We do not allow that in Pocket Lisp---every function
  // defined by the user takes a fixed amount of arguments.
  | procedure(pos: interval, name: text, parameters: list<text>, body: list<plisp_form>)

  // A `define` is a form that describes a local variable. Think of it like
  // a `let Name = Value` construct. Here we want the name of the variable
  // and which expression we should execute when computing its value.
  | define(pos: interval, name: text, value: plisp_form)

  // The `if` form describes a conditional like `(if test true false)`.
  // We require these to always have an "else" clause, so the user is
  // always in control of what's returned by evaluating this form, and
  // the form always has a defined value.
  | if(pos: interval, expr: plisp_form, consequent: plisp_form, alternate: plisp_form)

  // The `(quote expr)` form returns `expr` as a list, rather than evaluating
  // it.
  | quote(pos: interval, expr: plisp_form)

  // The `(callee a b c)` form represents the application of the
  // `callee` function to the arguments that follow it.
  | apply(pos: interval, callee: plisp_form, arguments: list<plisp_form>)

  // The `variable` form represents the dereference of a particular variable.
  | variable(pos: interval, name: text)

  // The `number` form represents an integer. Lingua doesn't really have
  // any features to transform text into numbers in its semantic actions,
  // so we just propagate the textual form of the number here and deal with
  // it inside of the virtual machine instead.
  | number(pos: interval, digits: text)

  // The `string` form represents a string. Here again we just keep the
  // contents exactly as it was in the source code. We don't deal with
  // escape codes at all for simplicity.
  | string(pos: interval, contents: text)

  // The `nil` form represents the empty list.
  | nil(pos: interval)

  // The `true` and `false` forms represents the boolean cases.
  | true(pos: interval)
  | false(pos: interval)

// 
// Technically, we wouldn't need to store the source information for atomic
// values, such as `nil` or `true`, because the evaluation of them can never
// fail. But, for consistency, it's good to have them in the AST.
// Some debugging tools may also make some use of them. For example, if you
// write a compiler that can optimise these forms, you might want to propagate
// the source information so that it's possible to build tools that show how
// the compiler transformed each piece of the original source into its target
// representation.
//

// ## The Pocket Lisp grammar
//
// Okay! Finally, it is time to move on to our actual grammar. The thing
// that decides what Pocket Lisp programs look like in their text form.
//
// In Lingua one defines a grammar by giving it a name and a "top level type".
// This is the type that we expect out of the grammar if we parse the top
// level rule. Our top-level rule is "Program" and we expect a plisp_program
// out of it.
//
// NOTE: This is likely to change as it doesn't work nearly as well if one
// wants to parse from a different rule.
//
grammar Pocket_Lisp : plisp_program {
  // Inside our grammar there will be a set of rules. Some rules, like
  // `letter` (any unicode letter), or `digit` (any ASCII digit, from 0 to 9),
  // are available by default without us having to define them.
  //
  // Rules can be a "Semantic" or "Lexical". The main difference between
  // them is that a "Semantic" rule automatically skips all whitespace
  // characters (using the `space` rule) before trying to match any of
  // its patterns. A "Lexical" rule requires any such thing to be made
  // explicit by the grammar writer.
  //
  // Semantic rules start with an upper-case letter, and they'll be our
  // friends here. Pocket Lisp is not a white-space sensitive language,
  // so we can leverage Semantic rules to make our grammar easier to
  // read.

  // ### The program
  //
  // A Pocket Lisp program is a sequence of "forms". It can, in fact, have
  // no forms at all---the empty program is valid.
  //
  // The way to read this is "the rule Program is made out of a sequence
  // of zero or more `Form` (we'll save this sequence as the variable `Forms`),
  // which should be followed by the end of the input, after skipping whitespace."
  // The pattern `A*` matches `A` zero or more times. The pattern `A+` would
  // match it one or more times.
  //
  // The `Name:Pattern` syntax is a Lingua idiom where what has been matched
  // by the pattern can be referenced as the given variable `Name`. This is
  // used in semantic actions. A semantic action is defined by `-> action`
  // after the patterns, and describes how we can transform a particular
  // rule match into an AST form.
  //
  // Lingua has a very restricted language for these semantic actions. The
  // two things that it makes possible are "creating nodes" (`plisp_program(A, B)`)
  // will create a new instance of the `plisp_program` node; and getting the
  // source information for the entire match (`meta`).
  //
  Program =
    | Forms:Form* end -> plisp_program(meta, Forms)

  // A form is any complete Pocket Lisp expression. Things that are defined
  // as macros in some Lisp dialects are just special syntactical forms in
  // Pocket Lisp. Thus `(define add [a b] ...)` is also covered as a special
  // case in the forms below.
  //
  // The use of the parameterised `id<word>` rule is important here. It means
  // that we'll match the piece of text `define`, but only if it's not
  // immediately followed by more letters and symbols.
  //
  // This is important because, being a PEG-based grammar, Lingua would
  // happily match `(define-all [a b c] (+ a b c))` as an instance of
  // `procedure`, where the name of the procedure is `-all`. This is
  // not what we want; we'd like such form to be parsed as an `apply` form
  // instead.
  //
  Form =
    | "(" id<"define"> N:name "[" Args:name* "]" Body:Form* ")"   -> plisp_form.procedure(meta, N, Args, Body)
    | "(" id<"define"> N:name V:Form ")"                          -> plisp_form.define(meta, N, V)
    | "(" id<"if"> T:Form C:Form A:Form ")"                       -> plisp_form.if(meta, T, C, A)
    | "(" id<"quote"> F:Form ")"                                  -> plisp_form.quote(meta, F)
    | "(" App:Form Args:Form* ")"                                 -> plisp_form.apply(meta, App, Args)
    | V:Value                                                     -> V
    | N:name                                                      -> plisp_form.variable(meta, N)
  
  // The choice of moving the `Value` part in its own rule here is quite
  // arbitrary. However, it's generally useful in more complex languages,
  // as there happens to be other portions of the grammar that allow
  // literal values to be used, but not full expressions. Of course,
  // these would also end up placing these literals in a type separate
  // from `plisp_form`.
  //
  Value =
    | X:number    -> plisp_form.number(meta, X)
    | X:string    -> plisp_form.string(meta, X)
    | X:boolean   -> X
    | id<"nil">   -> plisp_form.nil(meta)

  // Tokens are a special kind of Lexical rule where the entire matched
  // portion is returned as a piece of text. It does, however, follow
  // the same rules of PEG---if you have choices in it, we'll happilly
  // pick the first one that matches, even if a different choice would
  // have matched too!
  //
  token number =
    | digit+

  // In order to parse a string we want all of the contents between
  // the quotes.
  //
  string =
    | "\"" x:string_chars "\""  -> x

  // The string_chars is defined as a `token` rule for reasons similar to
  // the `number` rule. We don't want a list of individual characters, but
  // rather a single text value containing all of the content.
  //
  // The pattern is a bit contrived though. The way to read it is
  // "As long as it's not the `"` character, match any character zero or more
  // times". The `~Pattern` means that we assert that we cannot match the
  // Pattern, but also don't consume any input. That's why we need to follow
  // it with `any`, to specify that we do actually want to consume one character
  // if we ensure that it's not the double quote. The repeated grouping then
  // makes this happen over and over again.
  //
  // We don't need to worry about what this `(~"\"" any)` group returns here
  // because this is a token rule, and we only care about the portion of the
  // source code that was matched, but in a regular rule we'd need to move
  // it to a separate rule and make that explicit with a semantic action.
  //
  token string_chars =
    | (~"\"" any)*

  // A boolean can be either `true` or `false`.
  boolean =
    | id<"true">  -> plisp_form.true(meta)
    | id<"false"> -> plisp_form.false(meta)

  // A name can be anything that starts with a letter or symbol, and is
  // possibly followed by more letters, symbols, or digits. The reason
  // we don't allow digits at the beginning of a name is that something
  // like `123` would suddenly become both a valid name *and* a valid
  // number. We want to make sure our language is not ambiguous like that,
  // we don't have the developer always on the loop to disambiguate things.
  //
  token name =
    | (letter | symbol) (letter | symbol | digit)*

  // The `letter` rule is already provided by Lingua. But Lingua has it
  // mean "any unicode letter". That's far broader than what the Pocket Lisp
  // specification allows, so we change the rule here to allow only ASCII
  // letters.
  //
  // In a real language design, if the specification allows, you should
  // rather think about how you want to approach the idea of multi-cultural
  // software. This is, however, too big of a topic to discuss here---and
  // we're more focused on implementation than design here anyway.
  //
  // The `:=` operator here means that we're replacing the base `letter`
  // rule with a new definition. Lingua requires us to be explicit about
  // this.
  //
  token letter :=
    | "a" .. "z"
    | "A" .. "Z"

  // Likewise, the allowed symbols is very restricted to the ASCII set,
  // and likewise very skewed towards English speakers.
  //
  token symbol =
    | "!" | "%" | "*" | "-" | "_" | "+" | "=" | "^" | "?" | "/" | ">" | "<" | "|"

  // A comment in Pocket Lisp starts with a `;` and continues until the end 
  // of the line, like in most other Lisp dialects.
  //
  token comment =
    | ";" (~newline any)*

  token newline =
    | "\n"
    | "\r"

  // The `space` rule is provided by default to mean the ASCII space character,
  // and the null character. But since Lingua will use this rule to skip content
  // automatically in Semantic rules, it's useful to include comments in it as
  // well.
  //
  // The `+=` operator here means that, instead of replacing the `space` rule
  // entirely, we're just adding a new alternative to it. The `comment` rule
  // will be tried after all of the base `space` patterns are.
  //
  space += comment

  // Finally, the `id<word>` rule needs some especial attention. Lingua, like
  // Ohm, allows parameterised rules. Just like regular functions in
  // most programming languages, these are rules you can call by providing
  // parameters---the parameters themselves are more Lingua patterns.
  //
  // We can then choose how to use these pattern arguments. Here we take any
  // pattern that we call "word", and then try to match it, and immediately
  // assert that it's not followed by any letter, symbol, or digit. We're
  // pretty much ensuring that if someone uses `id<"define">` somewhere,
  // we'll not match `define-all`, and leave the `-all` part there hanging.
  //
  // Here we need to provide a semantic action. Lingua allows us to omit
  // it whenever the rule only wraps over another rule. But this one is
  // more complex and we need to be explicit about what it is that we
  // want to return when translating the match to an AST.
  //
  id<word> =
    | X:word ~(letter | symbol | digit) -> X
}

// # What's next?
//
// And that's it! We've defined what a Pocket Lisp program looks like, by
// way of defining a grammar, and we've also defined how we can translate
// whatever this grammar matches into a simpler structured form, the AST,
// which we can use in our virtual machine.
//
// But how does this parsing and translating actually work? Well, head over
// to the `vm try-parse: _` command in the `vm.crochet` file to continue your
// parsing adventures!
//